<h2 align="center">Infrastructure Big Data</h2>

<h3 align="center">Examen</h3>

Durée: 1h, documents autorisés
<u>**Understanding questions (6 points)**</u>
**Instructions: In the MCQ, several answers may be possible on some questions.**

<u>**Question 1**</u>

We consider the execution of the wordcount application on a Spark cluster composed of several servers. The execution should run faster than a centralized sequential version of wordcount :

- [ ] for all input files
- [ ] for input files with a minimal size
- [ ] for input files up to a maximal size



<u>**Question 2**</u>

In a Spark/HDFS cluster on top of Linux, what are the strong requirements (meanning it cannot run without
it)?

- [ ] ssh server installed on each node
- [ ] same type of processor on each node
- [ ] same number of processor on each node
- [ ] Java installed on each node



<u>**Question 3**</u>

In a distributed Spark/HDFS deployment :

- [ ] the Master daemon is running on the master node
- [ ] the NameNode daemon is running on all slave nodes
- [ ] the NameNode daemon is running on the master node
- [ ] the Worker daemon is running on all slave nodes
- [ ] the DataNode daemon is running on the master node



<u>**Question 4**</u>

In Spark, the `reduceByKey()` method:

- [ ] results into a dataset where each key is unique
- [ ] results into a dataset where the number of different keys is reduced
- [ ] gathers all the pairs on the master node
- [ ] distributes all the pairs over the slave nodes



<u>**Question 5**</u>

In Spark, the `reduceByKey (func)` method :

- [ ] can be applied to any JavaRDD
- [ ] can only be applied to a JavaPairRDD
- [ ] func is a function which aggregates 2 pairs into one pair
- [ ] func is a function which aggregates 2 values into one value



<u>**Question 6**</u>

In Spark, the `mapValues (func)` method:

- [ ] can be applied to any JavaRDD
- [ ] can only be applied to a JavaPairRDD
- [ ] func is a function which transforms a value into another value
- [ ] func is a function which aggregates 2 values into one value



#### Problem (14 points)

We consider a large file including meteorological data. Each line in the file provides an observation:

```
day month year temperature city
```

For instance : `12 07 1995 30 Paris` is an observation that on the 12th of july 1995, the temperaiure was 30 degrees in Paris.

You can extract the fields from a line L with `L.splitO[0]`, `L.splitO[1]`, etc.
Your algorithms start with the following `RDD` (initialized with a file available in HDFS) :

```java
JavaRDD<String> data = sc.textFile(inputFile);
```



<u>**Question 1**</u>
We want to compute for each city the average temperature. What's wrong in the following algorithm ? justify (1 point)

```java
JavaPairRDD<String, Integer> average = data.mapToPair(
    s -> new Tuple2<String, Integer> (s.split()[4],
                                      Integer.parseInt(s.split()[3])))
    .reduceByKey((t1,t2)->(t1 + t2)/2);
```



<u>**Question 2**</u>
Propose a correct solution to the previous question (1 point)



<u>**Question 3**</u>

We want to compute for each year the number of cities where temperature is measured (2 points). 

Result should be a `JavaPairRDD<year, count>`



<u>**Question 4**</u>
We want to extract the list of cites where 2022 was the warmest year (considering the maximal temperature) (3 points). 

Result should be a `JavaRDD<city>`